import pandas as pd

# 15 SPARK questions mapping
QUESTIONS = {
    1: {'item': 'Stability',    'question': 'When tasks come with clear structure, you feelâ€¦', 
        'choices': ['âš¡ Super-charged','ðŸ›‘ Short-circuited','ðŸŸ¡ Static','âš ï¸ Overloaded']},
    2: {'item': 'Trust',        'question': 'Collaborating with teammates you trust, you feelâ€¦',
        'choices': ['ðŸ¤ Aligned','ðŸ”’ Guarded','âž¡ï¸ Neutral','â“ Exposed']},
    3: {'item': 'Singularity',  'question': 'When you tunnel-vision on a solo project, you feelâ€¦',
        'choices': ['ðŸ”‹ Sharpened','ðŸª« Diffuse','âš–ï¸ Steady','â“ Uncertain']},
    4: {'item': 'Principles',   'question': 'Guided by our core principles, your dedication feelsâ€¦',
        'choices': ['ðŸš€ Committed','â›” Resistant','âž– Neutral','â“ Conflicted']},
    5: {'item': 'Passion',      'question': 'At the start of your day, your energy level isâ€¦',
        'choices': ['âš¡ Fired-up','ðŸ˜´ Drained','ðŸ”„ Steady','ðŸ’¤ Lethargic']},
    6: {'item': 'Purpose',      'question': 'When your work aligns with your purpose, you feelâ€¦',
        'choices': ['ðŸŽ¯ Centered','ðŸŒª Aimless','ðŸŸ¡ Grounded','ðŸŒ« Adrift']},
    7: {'item': 'Accountability','question': 'Owning your outcomes fully, you feelâ€¦',
        'choices': ['âœ… Effective','âŒ Ineffective','ðŸŽ‰ Valued','ðŸ™ Overlooked']},
    8: {'item': 'Appreciation', 'question': 'When peers recognize your efforts, you feelâ€¦',
        'choices': ['ðŸ‘ Seen','ðŸ‘» Invisible','ðŸ™‚ Acknowledged','ðŸ˜ Neutral']},
    9: {'item': 'Belonging',    'question': 'Being included in team decisions, you feelâ€¦',
        'choices': ['ðŸ¤— Embraced','ðŸš« Excluded','ðŸ˜Œ Accepted','ðŸ˜• Isolated']},
    10:{'item': 'Resilience',   'question': 'After a high-stress sprint, you feelâ€¦',
        'choices': ['ðŸ’ª Bounced-back','ðŸ˜© Drained','ðŸ”„ Stable','ðŸ˜“ Shaky']},
    11:{'item': 'Renewal',      'question': 'Following a recharge (break/weekend), you feelâ€¦',
        'choices': ['âš¡ Fully-charged','ðŸ˜ª Still-tired','ðŸ™‚ Refreshed','ðŸ˜ No-change']},
    12:{'item': 'Adaptability', 'question': 'When plans shift quickly, you feelâ€¦',
        'choices': ['ðŸ¤¸ Agile','ðŸ§± Rigid','âž– Neutral','ðŸ˜¤ Frustrated']},
    13:{'item': 'Connection',   'question': 'Striking up a genuine connection, you feelâ€¦',
        'choices': ['ðŸ”— Bonded','âšª Alone','ðŸ¤ Supported','â” Detached']},
    14:{'item': 'Candor',       'question': 'Sharing honest feedback, you feelâ€¦',
        'choices': ['ðŸ”Š Unfiltered','ðŸ”’ Reserved','âœ”ï¸ Clear','ðŸ˜¬ Awkward']},
    15:{'item': 'Contribution', 'question': 'Making an impact today, you feelâ€¦',
        'choices': ['âœ¨ Purposeful','âšª Ineffective','ðŸš€ Motivated','ðŸ™ Overlooked']}
}

# Map each emoji choice to a numeric score
CHOICE_TO_SCORE = {
    emoji: score for score, emojis in {
        4:['âš¡ Super-charged','ðŸ¤ Aligned','ðŸ”‹ Sharpened','ðŸš€ Committed','âš¡ Fired-up',
           'ðŸŽ¯ Centered','âœ… Effective','ðŸ‘ Seen','ðŸ¤— Embraced','ðŸ’ª Bounced-back',
           'âš¡ Fully-charged','ðŸ¤¸ Agile','ðŸ”— Bonded','ðŸ”Š Unfiltered','âœ¨ Purposeful'],
        3:['âš ï¸ Overloaded','â“ Exposed','â“ Uncertain','â“ Conflicted','ðŸ’¤ Lethargic',
           'ðŸŒ« Adrift','ðŸ™ Overlooked','ðŸ˜ Neutral','ðŸ˜Œ Accepted','ðŸ”„ Stable',
           'ðŸ˜ No-change','ðŸ˜¤ Frustrated','â” Detached','ðŸ˜¬ Awkward','ðŸš€ Motivated'],
        2:['ðŸŸ¡ Static','âž¡ï¸ Neutral','âš–ï¸ Steady','âž– Neutral','ðŸ”„ Steady',
           'ðŸŸ¡ Grounded','ðŸŽ‰ Valued','ðŸ™‚ Acknowledged','âž– Neutral','ðŸ”„ Stable',
           'ðŸ™‚ Refreshed','âž– Neutral','ðŸ¤ Supported','âœ”ï¸ Clear','ðŸš€ Motivated'], # adjust specifics
        1:['ðŸ›‘ Short-circuited','ðŸ”’ Guarded','ðŸª« Diffuse','â›” Resistant','ðŸ˜´ Drained',
           'ðŸŒª Aimless','âŒ Ineffective','ðŸ‘» Invisible','ðŸš« Excluded','ðŸ˜© Drained',
           'ðŸ˜ª Still-tired','ðŸ§± Rigid','âšª Alone','ðŸ”’ Reserved','âšª Ineffective']
    }.items() for emoji in emojis
}

# Scales for each framework
SCALES = {
  'SDT_Autonomy':     ['Stability','Adaptability'],
  'SDT_Competence':   ['Singularity','Contribution'],
  'SDT_Relatedness':  ['Trust','Appreciation','Belonging','Connection','Candor'],
  'MBI_Exhaustion':   ['Resilience','Renewal'],
  'MBI_Efficacy':     ['Accountability','Contribution'],
  'UWES_Vigor':       ['Passion'],
  'UWES_Dedication':  ['Principles','Purpose'],
  'UWES_Absorption':  ['Singularity']
}

def preprocess_raw_responses(raw: list) -> pd.DataFrame:
    """Convert raw list of {q#: emoji} into DataFrame of scores."""
    records = []
    for entry in raw:
        scored = {}
        for q_num, ans in entry.items():
            item = QUESTIONS[int(q_num)]['item']
            scored[item] = CHOICE_TO_SCORE.get(ans, None)
        records.append(scored)
    return pd.DataFrame(records)

def compute_ctt_indices(df: pd.DataFrame, items: list) -> dict:
    """
    Compute Cronbach's alpha and item statistics for given items,
    but guard against zero total variance (e.g. only one response).
    """
    sub = df[items]
    total = sub.sum(axis=1)
    var_items = sub.var(ddof=1)
    var_total = total.var(ddof=1)

    # Safeguard: if total variance is zero or not enough respondents, skip alpha
    if var_total == 0 or len(df) < 2:
        alpha = None
        item_total_corr = {item: None for item in items}
    else:
        n = len(items)
        alpha = (n / (n - 1)) * (1 - var_items.sum() / var_total)
        item_total_corr = {item: sub[item].corr(total) for item in items}

    return {
        'alpha': alpha,
        'item_total_corr': item_total_corr,
        'item_means': sub.mean().to_dict(),
        'item_vars': var_items.to_dict()
    }


def run_ctt_analysis_from_raw(raw: list) -> dict:
    df = preprocess_raw_responses(raw)
    return {scale: compute_ctt_indices(df, items) for scale, items in SCALES.items()}
